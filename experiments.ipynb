{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_csv, load_images, fill_na, plot_landmark, plot_landmark_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceLandmarkDataset(Dataset):\n",
    "    def __init__(self, device='cuda', transform=None):\n",
    "        self.device = device\n",
    "        self.landmarks_frame = load_csv()\n",
    "        fill_na(self.landmarks_frame)\n",
    "        images = load_images()\n",
    "        self.images =torch.from_numpy(images).type(torch.float)\n",
    "        \n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.landmarks_frame)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        img = self.images[idx]\n",
    "        landmarks = torch.from_numpy(self.landmarks_frame.iloc[idx].to_numpy()).type(torch.float64)\n",
    "        \n",
    "        sample = sample = {'image': img, 'landmarks': landmarks}\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(img, landmarks)\n",
    "        \n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyteruser/utils.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[i].fillna(df[i].mean(),inplace=True)\n",
      "/home/jupyteruser/utils.py:8: UserWarning: Reading `.npy` or `.npz` file required additional header parsing as it was created on Python 2. Save the file again to speed up loading and avoid this warning.\n",
      "  images = np.moveaxis(data_np['face_images'], -1,0)\n"
     ]
    }
   ],
   "source": [
    "ds = FaceLandmarkDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = ds.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([66.0336, 39.0023, 30.2270, 36.4217, 59.5821, 39.6474, 73.1303, 39.9700,\n",
       "        36.3566, 37.3894, 23.4529, 37.3894, 56.9533, 29.0336, 80.2271, 32.2281,\n",
       "        40.2276, 29.0023, 16.3564, 29.6475, 44.4206, 57.0668, 61.1953, 79.9702,\n",
       "        28.6145, 77.3890, 43.3126, 72.9355, 43.1307, 84.4858],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item['landmarks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise(iterable):\n",
    "    a = iter(iterable)\n",
    "    return zip(a,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(66.0335639098, 39.0022736842), (30.2270075188, 36.4216781955), (59.582075188, 39.6474225564), (73.1303458647, 39.9699969925), (36.3565714286, 37.3894015038), (23.4528721805, 37.3894015038), (56.9532631579, 29.0336481203), (80.2271278195, 32.2281383459), (40.2276090226, 29.0023218045), (16.3563789474, 29.6474706767), (44.4205714286, 57.0668030075), (61.1953082707, 79.9701654135), (28.6144962406, 77.3889924812), (43.3126015038, 72.9354586466), (43.1307067669, 84.4857744361)]\n",
      "[66.0335639098, 39.0022736842, 30.2270075188, 36.4216781955, 59.582075188, 39.6474225564, 73.1303458647, 39.9699969925, 36.3565714286, 37.3894015038, 23.4528721805, 37.3894015038, 56.9532631579, 29.0336481203, 80.2271278195, 32.2281383459, 40.2276090226, 29.0023218045, 16.3563789474, 29.6474706767, 44.4205714286, 57.0668030075, 61.1953082707, 79.9701654135, 28.6144962406, 77.3889924812, 43.3126015038, 72.9354586466, 43.1307067669, 84.4857744361]\n"
     ]
    }
   ],
   "source": [
    "p = []\n",
    "p_x = []\n",
    "\n",
    "for (x,y) in pairwise(item['landmarks'].numpy()):\n",
    "    p.append((x,y))\n",
    "    p_x.append(x)\n",
    "    p_x.append(y)\n",
    "\n",
    "print(p)\n",
    "print(p_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import torchvision.transforms.functional as F\n",
    "from PIL import Image\n",
    "\n",
    "class RandomRotate(object):\n",
    "    def __init__(self, degrees):\n",
    "        self.degrees = degrees\n",
    "    \n",
    "    def __call__(self, image, points):\n",
    "        angle = random.uniform(-self.degrees, self.degrees)\n",
    "        \n",
    "        image = F.rotate(image, points, resample=Image.BILNEAR)\n",
    "        \n",
    "        radians = math.radians(angle)\n",
    "        cos_theta = math.cos(radians)\n",
    "        sin_theta = math.sin(radians)\n",
    "        rotated_points = []\n",
    "        \n",
    "        for (x,y) in points:\n",
    "            x_rot = x * cos_theta - y * sin_theta\n",
    "            y_rot = x * sin_theta + y * cos_theta\n",
    "            rotated_points.append(x_rot)\n",
    "            rotated_points.append(y_rot)\n",
    "        \n",
    "        return {'image': image,  'landmarks': torch.tensor(rotated_points)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FacialFeaturesV6(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 512, 2)\n",
    "        self.conv2 = nn.Conv2d(512, 256, 2)\n",
    "        self.conv3 = nn.Conv2d(256, 128, 2)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv4 = nn.Conv2d(128, 128, 3)\n",
    "        self.conv5 = nn.Conv2d(128, 64, 3)\n",
    "        self.conv6 = nn.Conv2d(64, 32, 3)\n",
    "        self.batch_norm_l = nn.BatchNorm2d(128)        \n",
    "        self.batch_norm_m = nn.BatchNorm2d(64)        \n",
    "        self.batch_norm = nn.BatchNorm2d(32)        \n",
    "        self.fc1 = nn.Linear(32, 128)\n",
    "        self.fc2 = nn.Linear(128, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 64)\n",
    "        self.out_layer = nn.Linear(64, 30)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.batch_norm_l(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv4(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv5(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv6(x))\n",
    "        x = self.batch_norm(x)\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.relu(self.fc4(x))\n",
    "        x = self.relu(self.out_layer(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
